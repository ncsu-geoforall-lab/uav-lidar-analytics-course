<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<title>GIS/MEA 584: Mapping and Analytics Using UAS</title>

<link rel="shortcut icon" href=".././img/favicon.ico" />

<link href="../layout.css" rel="stylesheet" type="text/css" media="screen">
<link href="../style.css" rel="stylesheet" type="text/css" media="screen">

</head>

<body>

<div id="outercontainer">
<div id="container">

<header>
<div id="header-image">
    <h1>GIS/MEA 584:<br>Mapping and Analysis Using UAS</h1>
</div>

<nav>
<ul class="nav">
<li><a href="../index.html">Syllabus</a></li>
<!--
    Entries for topics index are created from files specified in build.sh
    (likely the schedule page), so check that when changing what schedule
    file to use here.
-->
<li><a href="../schedule_spring.html">Schedule</a></li>
<li><a href="../logistics.html">Course logistics</a></li>
<li><a href="../topics.html">Topics</a></li>
<!--<li><a href="../lectures.html">Lectures</a></li>-->
<li><a href="../projects.html">Projects</a></li>
<li><a href="../workshop.html">Workshop</a></li>
</ul>
</nav>

</header>

<main>
<!-- This is a generated file. Do not edit. -->
﻿<h2>Geoprocessing of the UAS data</h2>

<p>Completing this assignment you will generate orthomosaic and Digital
Surface Model using pictures taken from the UAS Trimble UX5 Rover
(Flight mission executed on September 22<sup>nd</sup> 2016). The Study area
is located at
<a href="https://www.google.com/maps/d/edit?mid=zi8EsFDQAyqo.kr7lL7Germeo">Lake Wheeler COA</a>. Additionally you will be able to see the processing
results in the generated report and optionally you will be able to
export also 3D model and Point cloud as well as Camera calibration and
orientation data.</p>

<p>The process can be very time consuming
(depending on computational power of your device and desired quality) 
<p>In order to minimize the processing time, we will process only fraction of the data collected and we will use imagery downsampled by 50%. It will allow us to generate outputs in the classroom. The resolution of ortophoto and DSM will be lower,  but the high quality and full extent otput of the processing are provided <a href="https://drive.google.com/open?id=0B1AfQGDB8tPXcHlzM01lY0pEd00"> here</a></p>


<p>
General workflow (with GCPs):

<ul>
    <li>Preparation
    <li>Stage 1: Building simple geometry (in order to place GCPs)
    <li>Stage 2: Placing GCPs
    <li>Stage 3: Building complex geometry
    <li>Stage 4: Exporting results
</ul>


<h3>Preparation</h3>

<h4>Data</h4>

<ul>
<li> OPTION 1: <strong>RECOMMENDED IN THE CLASSROOM</strong> - small area, photos downsampled to accelerate processing (but lower the resolution of the outputs)
	<ul>
   		<li><a href="https://drive.google.com/open?id=1SWDhzXMC66Gu__jSzD0rlf0kF1S8Vk3V">download data</a> - photos, log and coordinates of 3 GCPs
   	</ul>
<br>
<strong>Processing outputs</strong> from this option are provided <a href="https://drive.google.com/open?id=19z1wIMJ2Ehjdey4gHt1q9uZm0ZMWcfbL">here</a>
<br>
<br>
<li> OPTION 2: Small area (to accelerate processing), but photos not downsampled (to obtain the highest resolution of the outputs)
	<ul>
   		<li><a href="https://drive.google.com/open?id=1pKD7N0dzOZLQSWD4cj98UWrvrR62pxVW">download data</a>  - photos, log and coordinates of 3 GCPs
	</ul>
<br>
<li> OPTION 3: Full flight, photos original resolution <br>
<b>LONG PROCESSING TIME!</b>
	<ul>
   		<li><a href="https://drive.google.com/file/d/13wPTiJcBaxX2AZjibT9N7QIffHddoaqZ">download data</a>  - photos, log and coordinates of 12 GCPs
	</ul>
<br>
<li> OPTION 4: You can use your own data
<br>
</ul>




<h4>Software</h4>

<ul>
    <li>Agisoft Metashape Professional (<a href="http://www.agisoft.com/downloads/installer/">installer</a>)
</ul>

<h4>Preferences</h4>

<p>When launching Metashape for the first time, some settings need to
be adjusted to optimize performance. These settings need to be done
only once, at the first use of Metashape, and are loaded by default in
subsequent sessions.</p>

<p>Menu &gt; Tools  &gt;  Preferences</p>

<p>General tab:</p>

<ul>
    <li>Leave default
        (optional – white log to file: enabled, if you want to save the txt log file)
</ul>
<p>GPU tab:</p>

<ul>
    <li>Check the "USE CPU when performing GPU accelerated processing" option at the bottom
</ul>
<p>Network Tab:</p>

<ul>
    <li>Leave default
</ul>
	
<p>Appearance Tab:</p>

<ul>
    <li>Leave default (or adjust to personal taste)
</ul>
<p>Advanced tab:</p>

<ul>
	<li>Project Files
		<ul>
		<li>Keep key points: disabled
		<li>Keep depth maps: disabled
		<li>Store absolute image paths: disabled
		</ul>
	<li>Export/Import: enable all
	<li>Misceallaneous:
		<ul>
		<li>Enable fine level task division: enabled
		</ul>
</ul>

<figure>
<img src="img/geoprocessing/agi_preferences.JPG">
</figure>


<h3>Stage 1: Aligning photos in low quality (in order to place GCPs)</h3>

<p>In order to localize the GCPs first a preliminary simple model needs to be build.</p>


<h4>Adding photos</h4>

<p>Menu &gt;  Workflow &gt; Add Photos</p>

<p>Indicate the path to the folder (downloaded data) containing photos
and select them all.</p> <p>In the Reference pane, you can see that
the photos has been loaded, but the coordinate system indicates local
coordinates. It can be changed in the Settings.</p> <p>Click the
settings icon <img src="img/geoprocessing/settings_icon.png" class="icon">
&gt;  change coordinate system to WGS 84 (EPSG:4326)</p>

<figure>
<img src="img/geoprocessing/agi_reference.JPG">
</figure>


<h4>Loading camera positions</h4>

<p>Click Import button <img src="img/geoprocessing/import_icon.png" class="icon">
on the Reference pane toolbar &gt; select file
containing camera positions information (log file*) in the Open
dialog.</p>

<figure>
<img src="img/geoprocessing/log_load.PNG" width="50%">
</figure>

<p>*Agisoft support the camera orientation files in 5 formats: .csv, .txt, .tel, .xml and and .log. The default format of the Trimble Aerial Imaging log is .jxl. In order to convert the Trimble .jxl log
file please run <a href="https://github.com/wenzeslaus/jxl2csv">script by Vaclav Petras</a> or use <strong>provided already converted log in .txt format</strong></p>

<p>Make sure that the columns are named properly – you can adjust their
placement by indicating column number (top right of dialog box)</p>


<h4>Aligning photos</h4>

<ul>
    <li>Accuracy: Low
    <li>Check: Reference preselection
    <li>Key point limit: default
    <li>Tie point limit: default
    <li>Adaptive camera model fitting: enabled
</ul>

<p>Menu &gt; Workflow &gt; Align Photos</p>

<figure>
<img src="img/geoprocessing/align_photos.PNG">
</figure>
<p>Click Save <img src="img/geoprocessing/save_icon.png" class="icon"> in the toolbar</p>


<h3>Stage 2: Placing GCPs</h3>


<h4>Loading the GCPs coordinates</h4>

<p>Click Import button <img src="img/geoprocessing/import_icon.png" class="icon">
on the Reference pane toolbar &gt; select file
containing Ground Control Points coordinates in the Open dialog</p>
<figure>
<img src="img/geoprocessing/import_GCP.png">
</figure>

<p>Make sure that the columns are named properly – you can adjust their
placement by indicating column number (top right of dialog box).</p>

<p>This time you uncheck the <em>Rotation</em> box since GCPs are
stationary and do not need determining yaw pitch and roll angles.</p>

<p>The window with the message: <em>Can’t find match for ‘UAV 3’ entry.
Create new marker?</em>  will pop up.</p>

<figure>
<img src="img/geoprocessing/no_match_new_marker.png" width="50%">
</figure>

<p>Choose ‘Yes to All’ – it will create new marker for each of the
named GCPs from the file. They will be listed in Reference pane under
the list of photos.</p>


<h4>Indicating GCPs on the pictures</h4>

<p>Now you need to find each of the GCPs and indicate its localization
on all photos depicting it. You can also see the process on the <a href="https://www.youtube.com/watch?v=nnKJWev7Jyc">instructional video</a>  </p>

<p>The Model pane shows approximate positions of GCPs, it is better visible if
the ‘Show cameras’ option is disabled (Menu &gt; View &gt; Show/Hide
Items &gt; Show cameras)</p>

<p>
<figure>
<img src="img/geoprocessing/gcps_cameras.png" width=50%>
<img width="50%" src="img/geoprocessing/gcps_photo.png" ></p>
</figure>

<p>Choose in the context menu of the selected point on the list (right
click)  &gt;  Filter Photos by Marker.</p>

<figure>
<img src="img/geoprocessing/filter_photos_by_marker.png">
</figure>

<p>In the Photos pane
appear only the images in which the currently selected GCP is probably*
visible.</p>

<p>* <em>This is possible because our pictures are geotagged (log indicates the position of each photo), if you will be working with the pictures that are not geotagged or in the area that you don't know and are not able to "guess" which photo depicts which GCP, it is useful to build the dense ponint cloud or even mesh and texture (see the folloing steps) to see the preliminary model of the area in the Model pane, not just a sparse cloud (this is depicted on the figures above)</em></p>
<p>Open an image by double clicking the thumbnail. It will open in a
tab next to the Model pane.</p>

<p>The GCP will appear as a grey icon
<img src="img/geoprocessing/gcp_gray.png" class="icon">.
This icon needs to be moved to the middle of GCP visible on the photo</p>

<figure class="large">
<img src="img/geoprocessing/gcp_reposition.png">
</figure>

<p>Drag the marker to the correct measurement position. At that point,
the marker will appear as a green flag, meaning it is enabled and will
be used for further processing.</p>

<p>Double click on the next photo and repeat the steps. As soon as the
GCP marker position has already been indicated on at two images, the
proposed position will almost exactly match the point of measurement.
You can now slightly drag the marker to enable it (turning it into a
green flag) or leave it unchanged (gray marker icon) to exclude it from
processing.</p>

<p>Filter photos by each marker again. Agisoft adjusts the GCPs posisions on the run, so you can locate the GCP on additional images that will appear in the Photos pane.</p>

<p>In this sample processing we will include 4 GCPs. Mathematically, you need to indicate marker positions for at least 3
GCPs. Accurate error estimates can be calculated with at least 4 GCPs,
while often at least 5 are needed to cover the center of the project as
well, which reduces the chance of error propagation and resulting
terrain distortions especially on flat or undulating terrain types.</p>

<p>Click Save <img src="img/geoprocessing/save_icon.png" class="icon"> in the toolbar</p>


<h4>Optimizing alignment</h4>

<p>You can see the errors by clicking on the View Errors icon
<img src="img/geoprocessing/view_errors_icon.png" class="icon"></p>
<p>Best results are obtained when the alignment is first optimized based on the camera coordinates only, and a second time based on the GCP only.</p>



<p>Click Optimize icon <img src="img/geoprocessing/optimize_icon.png" class="icon"> in the Ground Control toolbar (ckeck all the boxes)</p>


<h4>Optimizing based on the GCP Markers</h4>

<p>In the Ground Control pane:</p>

<ul>
    <li>disable all the camera coordinates
        (select one &gt; press Ctrl+A &gt; right-click &gt; choose Uncheck).
    <li>enable all the GCP Marker coordinates
        (select one &gt; press Ctrl+A &gt; right-click &gt; choose Check).
</ul>

<p>Click Settings icon <img src="img/geoprocessing/settings_icon.png" class="icon"> in the Ground Control toolbar:</p>

<ul>
    <li>leave the  default values (Marker accuracy (m) = 0.005 m)
</ul>

<p>click Optimize icon <img src="img/geoprocessing/optimize_icon.png" class="icon"> in the Ground Control toolbar (leave all options at the default)</p>
<p>Click Save <img src="img/geoprocessing/save_icon.png" class="icon"> in the toolbar</p>
<p>You can now see how much the errors were reduced through optimization by clicking on the View Errors icon
<img src="img/geoprocessing/view_errors_icon.png" class="icon"></p>


<h3>Stage 3: Building complex geometry (for quality processing)</h3>


<p>Before starting the Build Dense Cloud step it is recommended to check
the bounding box of the reconstruction (to make sure that it includes
the whole region of interest, in all dimensions). The bounding box
should also not be too large (increased processing time and memory
requirements).</p>

<p>The bounding box can be adjusted using the Resize Region
<img src="img/geoprocessing/resize_region.png" class="icon"> and the Rotate Region
<img src="img/geoprocessing/rotate_region.png" class="icon"> tool from the
toolbar. Make sure that the base (red plane) is at the bottom.</p>

<figure>
<img src="img/geoprocessing/rotated_view.png">
</figure>

<p>The next steps will be time consuming (depending on the desired
quality and number of pictures). You can execute them one step at the
time, what would be explained below. You can also set a batch
processing that does not require user interaction until the end of
geoprocessing (especially useful in case of Ultra High quality that
requires even several days of processing). The batch processing will be
explained at the end of this section.</p>

<p>Menu &gt; Workflow &gt;  Build Dense Cloud</p>
<ul>
    <li>Quality = Medium* 
        <ul>
            <li>Medium (will downsample the images to get a 3D coordinate every 4 pixels
            <li>High (will downsample the images to get a 3D coordinate every 2 pixels;
                typically takes several hours but will give acceptable results for
                most cases),
                typically takes >10-20 hours) or
            <li>Ultra high (will calculate a 3D coordinate for every pixel in original
                imagery; may take more than a day or several days)
        </ul>
    <li>Depth filtering = Aggressive
</ul>

<p>*When working with large datasets take into consideration the RAM size requirements for the different
target qualities with respect to the number of images (in appendix in the <a href="https://www.agisoft.com/pdf/metashape-pro_1_5_en.pdf"> manual </a>or
in <a href="http://ncsu-geoforall-lab.github.io/uav-lidar-analytics-course/lectures/04_Imagery_Processing.html#/40"> lecture slides</a>).</p>

<figure>
<img src="img/geoprocessing/agi_build_dense_cloud.jpg">
</figure>

<p>Click Save <img src="img/geoprocessing/save_icon.png" class="icon"> in the toolbar</p>

<p>Menu &gt; Workflow &gt;  Build Mesh</p>

<ul>
    <li>Surface type: Height field
    <li>Source data: Dense cloud
    <li>Face count: Medium
    <li>Advanced options: leave default
</ul>

<p>*Face count set at “0” means that Metashape will determine an
optimum number of faces (but this may not be enough to describe all the
features on terrain)</p>

<figure>
<img src="img/geoprocessing/agi_build_mesh.jpg">
</figure>

<p>Menu &gt; Workflow &gt;  Build Texture</p>

<ul>
    <li>Mapping mode: Orthophoto
    <li>Blending mode: Mosaic (default)
    <li>Texture size/count: 4096
    <li>Enable color correction: disabled (unchecked)
</ul>

<p>Click Save <img src="img/geoprocessing/save_icon.png" class="icon"> in the toolbar</p>

<figure>
<img src="img/geoprocessing/agi_build_texture.jpg">
</figure>

<h4>Editing geometry</h4>

<p>Sometimes it is necessary to edit geometry before building texture
atlas and exporting the model.</p>

<p>If the overlap of the original images was not sufficient, the model
can contain holes. In this case to obtain holeless model use Close
Holes command. It is crucial if you want to perform any volume calculations - in this case, 100% holes need to be closed</p>

<p>Menu &gt;  Tools  &gt;  Mesh  &gt;  Close Holes</p>

<p>In Close Holes dialog select the size of the largest hole to be
closed (in percentage of the total model size). <strong>DO NOT CHOOSE 100% unless you are calculating volumes (then you have to close 100% holes)</strong></p>

<figure>
<img src="img/geoprocessing/agi_close_holes.jpg">
</figure>

<p>This does not apply to our data, since we have sufficient image
overlap. But due to strong dependency on weather conditions, the holes
in data are common with UAS.</p>

<h4>Building DEM</h4>

<p>Menu &gt;  Workflow &gt;  Build DEM</p>
<p>
In this step the parameters of the exported DEM are determined. In order to work in the commonly used in NC reference system, we will won't keep the porject's WGS84 system, but change it to NC State Plane (ESPG:3358)</p>
	
<figure>
<img src="img/geoprocessing/build_dem.jpg">
</figure>

<h4>Building Orthophoto</h4>

<p>Menu &gt;  Workflow &gt;  Build Orthophoto</p>
	<p>Orthophoto can be build only in the same coordinate system that the DEM</p>
	
<figure>
<img src="img/geoprocessing/build_ortho.jpg">
</figure>
<h4>Batch processing</h4>

<p>Menu &gt;  Workflow &gt;  Batch process  &gt; Add</p>

<p>
Batch processing allows to set multiple process
in the preset order and execute it one after another without user
intervention. All the parameters should be set the same as explained
above.</p>

<ol>
    <li>Optimize Alignment (if the GCPs were placed but the optimization not performed, otherwise:skip)
    <li>Build Dense Cloud
    <li>Build Mesh
    <li>Build Texture
    <li>Build Build DEM
    <li>Build Build Orthophoto
</ol>

<figure>
<img src="img/geoprocessing/batch.jpg">
</figure>
<!--
<p>
If the process takes really long time on your device,
you can cancel the processing and work with the project files saved on the
<a href="https://drive.google.com/open?id=0B1AfQGDB8tPXVlQxT0J5Z0prSlE">google drive</a>.
The only adjustment you need to make is to change the path of the pictures
to the localization of downloaded images on your computer.

<p>
In order to do that right clik on any of the pictures in the Pictures pane and choose <em>Change Path...</em> and in the dialog window mark the <em>All cameras</em> option. This will automatically apply the updated location to all the pictures in the project.</p>
<figure><img src="img/geoprocessing/agi_change_path.jpg"> </figure>
-->
<h3>Stage 4: Exporting results</h3>

<p>This option will be disabled if you are working in the demo version</p>


<h4>Orthomosaic</h4>

<p>File &gt;  Export Orthophoto &gt;  Export JPEG/TIFF/PNG…</p>

<ul>
    <li>Projection Type = geographic (default);
    <li>Datum = WGS 1984,
    <li>Write KML file (footprint) and World file (.tfw) = check if desired (if left unchecked,
        georeferencing information will still be contained in the GeoTIFF .tif file);
    <li>Blending mode = Mosaic (default)
    <li>Pixel size: leave default
</ul>

<figure>
<img src="img/geoprocessing/export_ortho.JPG">
</figure>

<p>Leave default values. Fill out the desired name and save as type TIFF/GeoTIFF (*.tif)</p>


<h4>Digital surface model</h4>

<p>Menu &gt;  File  &gt;  Export DEM…</p>

<figure>
<img src="img/geoprocessing/export_dem.JPG">
</figure>
<p>Leave default values. Fill out the desired name and save as type TIFF/GeoTIFF (*.tif)</p>


<h4>Generating report</h4>

<p>Menu &gt;  File &gt;  Generate report</p>
<p>Indicate the name and path for the PDF file</p>
<hr>
Processing outputs form the OPTION 1 (downsampled images) are provided <a href="https://drive.google.com/open?id=19z1wIMJ2Ehjdey4gHt1q9uZm0ZMWcfbL">here</a>
<hr>
The following export steps are optional.

<h4>Model</h4>

<p>Menu &gt;  File &gt;  Export model  &gt;  OBJ/FBX/KMZ…</p>

<p>Indicate the name, path and format of the output model</p>

<p>Metashape supports model export in the following formats: Wavefront
OBJ, 3DS file format, VRML, COLLADA, Stanford PLY, STL models, Autodesk
FBX, Autodesk DXF, Google Earth KMZ, U3D, Adobe PDF. Some file formats
(OBJ, 3DS, VRML, COLLADA, PLY, FBX) save texture image in a separate
file. The texture file should be kept in the same directory as the main
file describing the geometry.</p>
	
	3D Models are a great visualization tool. <a href="https://skfb.ly/69oyL">Model generated by following the assignment instructions</a> as well as <a href="https://skfb.ly/TEnq">model from full flight processing</a> can be viewed on sketchfab 


<h4>Point cloud</h4>

<p>Menu &gt;  File &gt;  Export points…</p>

<p>Indicate the name, path and format of the output file</p>

<p>Metashape supports point cloud export in the following formats:
Wavefront OBJ, Stanford PLY, XYZ text file format, ASPRS LAS, ASTM E57,
U3D,Potree,Metashape OC3, PDF,</p>


<h4>Camera calibration and orientation data</h4>

<p>Menu &gt; Tools &gt; Export &gt; Export Cameras</p>

<p>Indicate the name, path and format of the output file</p>

<p>Metashape supports camera data export in the following formats:
Metashape structure file format (XML based), Bundler OUT file format,
CHAN file format, Boujou TXT file format, Omega phi Kappa text file
format, PATB Exterior orientation, BINGO Exterior orientation, AeroSys
Exterior orientation, Inpho project file.</p>


</main>

<footer>

<nav>
<ul>
<li><a class="term-changes" href="https://moodle-courses1718.wolfware.ncsu.edu/course/view.php?id=4709">Moodle site</a></li>
<li><a href="http://help.ncsu.edu/">Computing Help</a></li>
<li><a href="https://geospatial.ncsu.edu/">GIST Home</a></li>
<li><a href="http://www.ncsu.edu/policies/prr-disclaimer.php">Disclaimer</a></li>
<li><a href="http://oit.ncsu.edu/itaccess">Accessibility</a></li>
<li><a href="https://github.com/ncsu-geoforall-lab/uav-lidar-analytics-course" title="Source code for web pages on GitHub">
        <img src="../img/github_logo.png" alt="GitHub Octocat logo">
    </a>
</li>
<li title="Copyright and license (not applicable to linked materials)">
    &copy; 2018
    <a href="https://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA</a>
    <a href="https://geospatial.ncsu.edu/geoforall/">NCSU GeoForAll Lab</a>
</li>
</ul>
</nav>

</footer>

</div>
</div>

</body>
</html>
