<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<title>GIS/MEA 584: Mapping and Analytics Using UAS</title>

<link rel="shortcut icon" href=".././img/favicon.ico" />

<link href="../layout.css" rel="stylesheet" type="text/css" media="screen">
<link href="../style.css" rel="stylesheet" type="text/css" media="screen">

</head>

<body>

<div id="outercontainer">
<div id="container">

<header>
<div id="header-image">
    <h1>GIS/MEA 584:<br>Mapping and Analysis Using UAS</h1>
</div>

<nav>
<ul class="nav">
<li><a href="../index.html">Syllabus</a></li>
<!--
    Entries for topics index are created from files specified in build.sh
    (likely the schedule page), so check that when changing what schedule
    file to use here.
-->
<li><a href="../schedule_spring.html">Schedule</a></li>
<li><a href="../logistics.html">Course logistics</a></li>
<li><a href="../topics.html">Topics</a></li>
<!--<li><a href="../lectures.html">Lectures</a></li>-->
<li><a href="../projects.html">Projects</a></li>
<li><a href="../workshop.html">Workshop</a></li>
</ul>
</nav>

</header>

<main>
<!-- This is a generated file. Do not edit. -->
<h2>Processing of UAS imagery in OpenDroneMap</h2>


Outline:
<ul>
    <li> Setup VCL with Web OpenDroneMap (WebODM)</li>
    <!-- <li>Preprocess images to include GPS coordinates</li> -->
    <!-- <li>Setup WebODM</li> -->
    <li>Explore results from WebODM</li>
    <li>Run ODM from command line (optional)</li>
</ul>

Data: 
<!-- <p>Don't download this data on your computer, we will download it on VCL during assignment. -->
<ul>
    <li>Sample of June 2015 UAV flight:
         <a href="https://drive.google.com/a/ncsu.edu/file/d/1xYhNBBDVPP4UG2aiSjcZ_tTOm4gnQcMz/view?usp=sharing">photos and log</a>.</li>
    <li> <a href="http://fatra.cnr.ncsu.edu/uav-lidar-analytics-course/mid_pines_lidar2013_dsm.tif">2013 lidar interpolated DSM</a>,
        use r.import.
    <li>Processed results on drive: <a href="https://drive.google.com/open?id=1uwjfPGL5knydpZoU_zU0Fopzl5tSRl9t">odm.zip</a></li>
</ul>
<p>
Tools:
<ul>
    <li><a href="http://wingrass.fsv.cvut.cz/grass74/">GRASS GIS 7</a></li>
    <li><a href="http://opendronemap.github.io/odm/">OpenDroneMap</a> (we will install it on VCL)
        <iframe width="560" height="315" src="https://www.youtube.com/embed/0UctfoeNB_Y" frameborder="0" allowfullscreen></iframe>
</ul>



<!-- We will reconstruct DSM and create orthophoto in <a href="http://opendronemap.github.io/odm/">
OpenDroneMap</a> - open source toolkit for processing civilian drone imagery.
<p> -->


<h3>Preparing Docker and data</h3>
We will use <a href="https://vcl.ncsu.edu/">VCL</a> with Ubuntu OS, select <em>Agisoft Photoscan &amp; GRASS GIS - Ubuntu</em>
 (Ubuntu 16.04 LTS). Alternatively, use <em>OSGeo Live</em>, or <em>Ubuntu 16.04 LTS</em> but they provide less computing resources.
 You can request it for 1 day or more if you plan to go back to the assignment later.
 You will need a remote desktop software to run the VCL, it won't run in your browser.

<ol>
<li>Once you start Ubuntu, it will ask about keyring, click Cancel,
    then it asks about panel, say Use default.
    Go to Applications - Terminal Emulator,
    from this terminal window we will first install Docker from packages:

<pre><code>sudo apt-get install -y docker.io git python-setuptools python-pip
</code></pre>

We also need docker-compose:
<pre><code>sudo curl -L https://github.com/docker/compose/releases/download/1.18.0/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose
</code></pre>

To properly setup Docker in terms of user permissions, run:
<pre><code>sudo groupadd docker
sudo usermod -aG docker $USER
</code></pre>
To make sure the permission changes take place, you need to log out (Applications - Log out)
and then log in back. Then start the terminal again.
</li>

<!--

-->
<li>Get your data ready:
    On your computer (not VCL), download the <a href="https://drive.google.com/a/ncsu.edu/file/d/1xYhNBBDVPP4UG2aiSjcZ_tTOm4gnQcMz/view?usp=sharing">photos and log</a>
    for the class. Unzip them.</li>
<li>Finally, we will used prepared GCP file, which is in your folder with images.
    WebODM has an graphical interface for creating this file as well. The format of the GCP file is:
<pre><code>WGS84 UTM 17N
708477.2014791 3956143.22167367 111.888 1341 722 dsc01547.jpg
...
</code></pre>
where the numbers represent GCP X, GCP Y, GCP altitude, image column, image row, image name.
</li>
</ol>

<!--
<h3>Preprocesing of images</h3>
Before we can run OpenDroneMap, we need to preprocess the images.

<ol>
<li>OpenDroneMap takes GPS position and focal length from images, not from the log.
First we check whether the GPS data are in the
<a href="https://en.wikipedia.org/wiki/Exif">EXIF data</a> of the images.
You can go to file manager and right click to display properties of an image to see the
EXIF information. Alternatively, use a command line tool <em>jhead</em>.
We first install it, switch directory and run it twice, once with verbose setting
to see more details.
<pre><code>sudo apt-get install -y jhead
cd ~/odm/images
jhead dsc01648.jpg
jhead -v dsc01648.jpg
</code></pre>


Since the images don't have GPS information in their
EXIF data, we will have to add them there.</li>

    <li>First, we will need to convert the <code>.jxl</code> log
file into a CSV file using script
<a href="https://github.com/wenzeslaus/jxl2csv">jxl2csv.py</a>.
<pre><code><span class="comment"># change directory to folder with images
</span>cd ~/odm/images
<span class="comment"># download the script
</span>wget https://raw.githubusercontent.com/wenzeslaus/jxl2csv/master/jxl2csv.py
<span class="comment"># run the script - full.jxl is input, full.csv is output
</span>python jxl2csv.py full.jxl full.csv
<span class="comment"># convert uppercase file names to lowercase to match the JPG files
</span>head full.csv
tr A-Z a-z &lt; full.csv &gt; full_lowercase.csv
head full_lowercase.csv
</code></pre>
</li>
    <li>Then we need to upload the focal length and GPS into the photos' EXIF data,
because our photos don't have this information in EXIF. We will use a script
<a href="https://github.com/petrasovaa/write-EXIF-GPS">write-EXIF-GPS.py</a>
for that. There will be some warnings about missing files and truncating the
entry, ignore them.
Warning: script <code>write_exif_GPS.py</code> is not general, focal length and camera model are hardcoded
and must be changed for different cameras.
<pre><code><span class="comment"># download the script
</span>wget https://gist.githubusercontent.com/petrasovaa/d7cbd64014f4bef24b1c/raw/write_exif_GPS.py
<span class="comment"># install libraries the script requires
</span>sudo apt update &amp;&amp; sudo apt install -y proj-bin exiv2
<span class="comment"># run the script, input is the CSV we created from jxl file
</span>python write_exif_GPS.py full_lowercase.csv
</code></pre>

Now check again the EXIF information:
<pre><code>jhead dsc01648.jpg
</code></pre>

</li>

    <li>Finally, we will need to identify GCPs in the images.
    To georeference the DSM, we need to prepare a text file with each GCP on one line,
    where the numbers represent GCP X, GCP Y, GCP altitude, image column, image row, image name.
    For example:
<pre><code>636795.964 219156.17 105.06 1588 2066 dsc01861.jpg
</code></pre>
    Download the <a href="./resources/gcp_list.txt">prepared GCP file here</a>.
    This file was manually prepared by identifying the GCPs on selected images.
<pre><code>wget http://ncsu-geoforall-lab.github.io/uav-lidar-analytics-course/assignments/resources/gcp_list.txt
</code></pre>
    </li>
</ol>
Now we are ready to run OpenDroneMap!
-->

<h3>Running WebODM</h3>

On VCL, in terminal, download WebODM code using Git:

<pre><code>cd ~
git clone https://github.com/OpenDroneMap/WebODM --config core.autocrlf=input
</code></pre>

Go to the code directory:

<pre><code>cd WebODM
</code></pre>

Start WebODM (be patient):

<pre><code>./webodm.sh start &amp;
</code></pre>
<p>
Further steps:
<ol>
<li>On your host computer (not VCL) go to the IP address of the VCL
     (you get that number when you click Connect when you access your VCL reservation) and add ":8000", so it will
 be something like 152.7.86.219:8000
</li>
<li> You will be prompted to create an
administrator account. Create it. It will be the only account we will
need for the exercise.</li>
<li>Alternatively, in the browser window on your VCL, go to
<tt>http://localhost:8000</tt>.</li>

<li>
Upload images to the task which is already there or create a new one. Include gcp_list.txt file.
<!-- Don't include the GCP file (there is currently a problem with it, which is being fixed). -->
</li>

<!-- <li>In Options, find option force-ccd and put 23.4 there (ccd width of our camera model, it's not in their database)</li> -->
<li>
In Resize images, change the size of images to 1000 to speed up the upload and
computation (this reduces the quality of the images and the whole reconstruction).</li>

<!-- <li>To follow the
processing, you can access WebODM from outside the VCL machine. Enter
the VCL machine IP address as URL to your web browser and add
<tt>:8000</tt> to it. You should get a login page and you should be able
to log in using the admin account credentials you created earlier.</li> -->

<li>Once your WebODM is finished, you can explore data within WebODM (in VCL or outside),
specifically the orthopohoto, point cloud, mesh and DSM.
You can also download them, for next steps download the DSM (tiff), orthophoto, and mesh.</li>
</ol>


<h3>Using the results from WebODM</h3>
If the processing is still running and you can't wait, download precomputed results &mdash;
 <a href="https://drive.google.com/open?id=1uwjfPGL5knydpZoU_zU0Fopzl5tSRl9t">odm.zip</a> and unzip in your home folder.



<h4>View point cloud</h4>
<p> Look first at the point cloud (<code>odm_georeferenced_model.laz</code>) in <a href="plas.io">plas.io</a>.


<h4>View mesh</h4>
To view and edit the mesh stored as OBJ we can use MeshLab.
MeshLab can also import the point cloud stored as PLY file.
In VCL terminal run to install:

<pre><code>sudo apt-get install -y meshlab
</code></pre>
You can then find it in Applications - Graphics.
Import mesh <code>odm_textured_model.obj</code>.


<h4>View DSM</h4>
<p>Start GRASS GIS (Applications - Education), create GRASS GIS database directory <code>grassdata</code>
in your home folder. Create new Location (<em>New</em> button on the left)
based on the DSM. Type projection name and then select 'Read projection and datum terms from a georeferenced data file'
and browse to <code>dsm.tif</code>.
<p>
Start GRASS GIS in PERMANENT and set your working directory (Settings - GRASS working environment) where you have
your odm folder. Import generated orthophoto:
<pre><code>r.import input=odm_orthophoto.tif output=odm_ortho
g.region raster=odm_ortho.1
r.mask raster=odm_ortho.4 maskcats=255
r.composite red=odm_ortho.1 green=odm_ortho.2 blue=odm_ortho.3 output=ortho
r.mask -r
</code></pre>


Now import DSM file:
<pre><code>r.import input=dsm.tif output=odm_dsm
</code></pre>
<!-- <p>
Now import LAS file and fill holes using IDW interpolation. Alternatively you could
import points with <a href="https://grass.osgeo.org/grass74/manuals/v.in.lidar.html">v.in.lidar</a> and then interpolate using 
<a href="https://grass.osgeo.org/grass74/manuals/v.surf.rst.html">v.surf.rst</a>.
<pre><code>r.in.lidar -eo input=georeferencing/odm_georeferenced_model.las output=odm_elev method=mean resolution=0.5
g.region raster=odm_elev
r.fill.stats -k input=odm_elev output=odm_filled distance=3 mode=wmean power=2.0 cells=8
</code></pre> -->

Compare the DSM with lidar. Import the <a href="http://fatra.cnr.ncsu.edu/uav-lidar-analytics-course/mid_pines_lidar2013_dsm.tif">lidar DSM</a>,
browse to the file using GUI or you have to have it
in your current working directory.
<pre><code>r.import input=mid_pines_lidar2013_dsm.tif
r.mapcalc "diff = odm_dsm - mid_pines_lidar2013_dsm"
r.colors map=diff color=differences
</code></pre>



<p>
<center>
<img src="../img/opendronemap_midpines_dsm.png" style="width: 70%;">
<br>
Example resulting shaded DSM created in GRASS GIS based on a point cloud
obtained by the above process.
</center>

<p>
<center>
<img src="../img/opendronemap_midpines_point_cloud.png" style="width: 70%;">
<br>
Example resulting shaded DSM created in GRASS GIS based on a point cloud
obtained by the above process.
</center>



<h3>Running OpenDroneMap in command line (optional)</h3>
We will run OpenDroneMap in a command line using <a href="https://www.docker.com/">Docker</a> to simplify setup (the internally used operating system is Ubuntu).
To setup ODM:
<ol>
<li>We will download a pre-built image of OpenDroneMap:
<pre><code>docker pull opendronemap/opendronemap
</code></pre>
</li>

<li>Either in file manager or in command line create a directory
    called <code>odm</code>. Put it somewhere with enough disk space (home folder).
    Inside the <code>odm</code> directory create directories
    <code>images</code>, <code>orthophoto</code>,
    <code>georeferencing</code>, and <code>texturing</code>.
    On unix-like systems, creating the directories would look something
    like this:
<pre><code>cd
mkdir odm
cd odm
mkdir images
mkdir orthophoto
mkdir georeferencing
mkdir texturing
</code></pre>
</li>


<li>Get your data ready:
    Open browser (Applications - Internet - Firefox).
    Download the <a href="https://drive.google.com/a/ncsu.edu/file/d/1xYhNBBDVPP4UG2aiSjcZ_tTOm4gnQcMz/view?usp=sharing">photos and log</a>
    for the class. Unzip them. Move the images and all the other files
    to the <code>images</code> directory (no subdirectories).
    On unix-like systems, moving of the files would look something like
    this:
<pre><code>mv unzipped-dir/* images/
</code></pre>

You should see a lot of .jpg and couple other files listed when you run:
<pre><code>ls ~/odm/images
</code></pre>
</li>
</ol>

We will use default parameters. To review parameters run:
<pre><code>docker run -it --rm opendronemap/opendronemap --help
</code></pre>

    Check if your previous computation in WebODM  is still running. If yes, please wait until it's done,
    because you wouldn't have sufficient resources for both reconstructions.
    Once it's finished, you can start processing, it should take roughly 30 mins.
<p>
 We will keep default values, but we need to specify the path to file with GCPs.
Some explanation of the <code>docker run</code> command:
<ul>
    <li><code>-v</code> links our directory <code>images</code> to
    a directory inside Docker container</li>
    <li>The string <code>$(pwd)</code> in the commands stands for the current
    working directory which should be the <code>odm</code> directory
    we created earlier.</li>
</ul>

<pre><code>cd ~/odm
docker run -it --rm -v $(pwd)/images:/code/images -v $(pwd)/orthophoto:/code/odm_orthophoto -v $(pwd)/georeferencing:/code/odm_georeferencing -v $(pwd)/texturing:/code/odm_texturing $(pwd)/dem:/code/odm_dem opendronemap/opendronemap --mesh-size 100000 --resize-to 1000 --dsm --gcp /code/images/gcp_list.txt --force-ccd 23.4
</code></pre>

OpenDroneMap will do the processing in parallel. However, each process
requires certain amount of memory (RAM) based on the size of input
images. If you want to limit the memory usage, you need to limit the
number of processes using the <code>--opensfm-processes</code> command
line option.

<p>
Open System Monitor (Applications - System - System Monitor), go to tab Resources.
You can observe here how ODM uses parallel processing for different parts of the
computation.


<p>
Once computed, all results are stored in the <code>odm</code> directory,
specifically in <code>orthophoto</code>, <code>georeferencing</code>,  <code>texturing</code>, and <code>dem</code>
subdirectories.



</main>

<footer>

<nav>
<ul>
<li><a class="term-changes" href="https://moodle-courses1718.wolfware.ncsu.edu/course/view.php?id=4709">Moodle site</a></li>
<li><a href="http://help.ncsu.edu/">Computing Help</a></li>
<li><a href="https://geospatial.ncsu.edu/">GIST Home</a></li>
<li><a href="http://www.ncsu.edu/policies/prr-disclaimer.php">Disclaimer</a></li>
<li><a href="http://oit.ncsu.edu/itaccess">Accessibility</a></li>
<li><a href="https://github.com/ncsu-geoforall-lab/uav-lidar-analytics-course" title="Source code for web pages on GitHub">
        <img src="../img/github_logo.png" alt="GitHub Octocat logo">
    </a>
</li>
<li title="Copyright and license (not applicable to linked materials)">
    &copy; 2018
    <a href="https://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA</a>
    <a href="https://geospatial.ncsu.edu/geoforall/">NCSU GeoForAll Lab</a>
</li>
</ul>
</nav>

</footer>

</div>
</div>

</body>
</html>
